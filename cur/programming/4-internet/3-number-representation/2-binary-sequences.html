<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<script type="text/javascript" src="/bjc-r/llab/loader.js"></script>
        <title>Unit 4 Lab 3: Number Representation, Page 2</title>
	</head>

	<body>
		<h2>Binary Sequences</h2>
		<div class="todo">Here are the EKs for LO (2.1.2), which is what we'd planned to cover here:
            <ul>
				<li><strong>EK 2.1.2A</strong> A finite representation is used to model the infinite mathematical concept of a number.</li>
                <li><strong>EK 2.1.2B</strong> In many programming languages, the fixed number of bits used to represent characters or integers limits the range of integer values and mathematical operations; this limitations can result in overflow or other errors.</li>
                <li><strong>EK 2.1.2C</strong> In many programming languages, the fixed number of bits used to represent real numbers (as floating-point numbers) limits the range of floating-point values and mathematical operations; this limitations can result in round off and other errors.</li>
                <li><strong>EK 2.1.2D</strong> The interpretation of a binary sequence depends on how it is used.</li>
                <li><strong>EK 2.1.2E</strong> A sequence of bits may represent instructions or data.</li>
                <li><strong>EK 2.1.2F</strong> A sequence of bits may represent different types of data in different contexts.</li>
            </ul>
        </div>
        <div class="forYouToDo" id="first">
			<ol>
				<li>Load <a class="run" href="/bjc-r/prog/4-internet/U4l3-Big Numbers.xml">this project</a>.</li>
				<li>The <em>factorial</em> of a positive integer <em>n </em>(written &quot;<em>n</em>&thinsp;!&quot;) is the product of all the integers from 1 to <em>n</em>:<br /> 
				  5! = 1 × 2 × 3 × 4 × 5 = 120<br />
				  Write a reporter <img src="/bjc-r/img/4-internet/bang.png" alt="( ( ) !)"> that computes the factorial of its input. (One way to do this uses a script variable and a <code>for</code> loop. You'll learn another way in Unit 7.) Debug it using small inputs; make sure that you get<br />
              <img src="/bjc-r/img/4-internet/bang5.png" alt="( (5) !) -> 120"></li>
				<li>Try some larger inputs:<br />
                <img src="/bjc-r/img/4-internet/bang10.png" alt="( (10) !) -> 3628800"></li><br />
                <img src="/bjc-r/img/4-internet/bang20.png" alt="( (20) !) -> 2432902008176640000"></li><br />
                <img src="/bjc-r/img/4-internet/bang30.png" alt="( (30) !) -> 2.6525285981219103e+32"></li>			   
			</ol>
        </div>
<p>Huh?

	Apparently 30! is a decimal fraction, 2.65..., and what's that &quot;e+32&quot; at the end?
<p>What you're seeing is called <em>scientific notation,</em> The &quot;e&quot; means &quot;times ten to the power,&quot; so this number is
<p>2.6525285981219103 × 10 <sup>32</sup>
	= 265252859812191030000000000000000
<p>So why did Snap<em>!</em> display 20! in ordinary whole number representation, just a string of digits, but 30! in scientific notation? You already know that computers use bits to store information, including numbers. The new thing for you to learn is that every computer model is designed with a certain<strong> width</strong>, the number of bits that the processor reads from memory or writes into memory at a time. That number of bits is called a <strong>word</strong>. As we write this in 2016, most new computers are 64 bits wide, but there are still a lot of 32-bit computers around.  The first microcomputer, the Intel 4004, first sold in 1971, was four bits wide!
<div class="takeNote"><p>If you got an answer in scientific notation for 20!, you're using a 32-bit computer.</p></div>
<div class="endnote">
<p>It's not a law of nature that processor widths have to be a power of two; some of us are old enough to remember 12-bit, 36-bit, and 60-bit computers (not microcomputers; the old ones you see in old movies that filled a large room). But modern personal computers started at 8 bits and the widths have been doubling with each new generation.</p></div>
<p>On a 64-bit computer, if you want to represent positive and negative integers, you can fit 2<sup>63</sup>=9223372036854775808 of each. This is about 9 quintillion, 9×10<sup>18</sup>. (The largest representable positive integer is actually one less than that, because zero takes up one of the positive integer codes.) That means that the 19-digit value of 20! just fits in a word, but the 33-digit 30! doesn't.</p>
<div class="forYouToDo">
<ol start="4">
  <li>What's the first integer whose factorial doesn't fit in a word?</li> </ol></div>
 <p>All computers have a finite amount of memory. After all, there are only a finite number of atoms on Earth!  So it's not a surprise that there's a limit to the size of integers a computer can represent exactly.  But that limit is way more than 64 bits; your computer probably has 137 <em>billion</em> or more bits of memory.  Why can't programming languages just use more than one word if necessary to represent an integer? 
 <p>They can.  It's just that computers can add two words in a single machine intruction, whereas the programmer of the language interpreter has to work a little harder to do arithmetic on multiple-word values. (A multiple-word integer value is called a <strong>bignum</strong>.) <em>Good</em> programming languages do that; remember that the whole point of computer science is abstraction, and one important kind of abstraction is protecting the user from having to know about hardware limitations.  Alas, there aren't very many good programming languages; probably all the languages you've heard of limit integer values to what fits in a word. 
 <div class="takeItFurther"><img class="imageRight" src="/bjc-r/img/icons/tough-stuff-mini.png" alt="Tough Stuff" title="Tough Stuff" /><p>The paradigmatic example of a good programming language is <a href="http://groups.csail.mit.edu/mac/projects/scheme/index.html">Scheme</a>. You can learn it from <a href="https://mitpress.mit.edu/sicp/full-text/book/book.html">the best computer science book ever written</a>.</p></div>
 <div class="takeNote">This business about good and bad languages isn't just a question of taste; it can be a matter of life and death.  Between 1985 and 1987, a therapeutic X-ray machine called the Therac-25 killed four patients and seriously injured two more because of several bugs in its software; one of the bugs was that a usage counter kept in an eight-bit-wide variable would reach its maximum value of 127 and then
 <strong>overflow</strong> to zero instead of 128.  When the variable was zero, an important safety check was not performed.  This would not have happened if the Therac software had been written in a good programming language.</div>
 <div class="forYouToDo">
  <ol start="5">
  <li>Click on this block in the scripting area:<br />
  <img src="/bjc-r/img/4-internet/bignums-true.png" alt="USE BIGNUMS &lt;true&gt;"> 
  </li>
  <li>Now try 30! again.<br /><img src="/bjc-r/img/4-internet/bang30-bignum.png" alt="((30) !) -&gt; 265252859812191058636308480000000"><br />
  Note that this (exactly correct) value is different from the (rounded off) floating point value above.</li>
  <li>Try 200!. The resulting speech balloon won't fit on your screen, so do it this way:
  <ol type="a">
    <li>Hold down the shift key and right-click or control-click the <code>!</code> block.</li>
    <li>In the menu that appears, click on the red &quot;script pic with result&quot; item.</li>
    <li>You'll see a new browser tab with an unreadably small picture. Click on the picture and it should expand to readable size with a scroll bar at the bottom of the screen.</li></ol></li>
    <li>How many digits are there in 200!&thinsp;? Hint: Don't count by hand; you have a computer.</li>
  <li>Turn bignums off and try 200! again.<br /><img src="/bjc-r/img/4-internet/200bang-fixnum.png" alt="((200) !) -&gt; infinity"></li></ol></div>
   

<p>What's up with <em>that?</em> We've already seen that 200!, although it's very large, isn't infinite. Computers are perfectly capable of handling it. As you might guess, this is also the result of a size limitation. The <strong>floating point</strong> representation that computers use for non-integers (and, in a non-bignum language, integers that are too big for the integer representation) can only represent numbers up to about 10<sup>308</sup>. But 200! is about 8×10<sup>374</sup> (as you should know if you did problem 8). If the result of a computation is bigger than that, floating point hardware returns a special code that represents Infinity.</p>
<div class="takeNote">
  <p>Floating point is essentially a binary version of scientific notation. A 64-bit floating point value has a <strong>sign bit</strong> that's 0 for a positive number or 1 for a negative number; an 11-bit <strong>exponent</strong> part representing the range from 2<sup>-127</sup> to 2<sup>127</sup>; and a 52-bit <strong>fraction</strong> or <strong>significand</strong> part representing the actual digits of the number. There are special codes for Infinity, -Infinity (smaller than any finite value), and &quot;Not a Number,&quot; the result of illegal computations such as 0/0. (We're leaving out some details about special cases that aren't important in this course.)</p>
  <p>Not only are there infinitely many real numbers, but there are infinitely many of them between any two consecutive integers&mdash;between 2 and 3, for example. This means that <em>most</em> real numbers, not just especially large ones, are not exactly representable in this format. Think about the decimal representation of 1/3, 0.33333... It has infinitely many digits, so the closest you can come in floating point isn't <em>exactly</em> 1/3. That's why even good programming languages set a limit to the number of digts representable in floating point notation.</p></div>
  <div class="forYouToDo">
  <p>On the other hand, fractions such as 1/3 <em>can</em> be represented exactly using a pair of integers, one for the numerator and one for the denominator.</p>
<ol start="10">
<li>Try<img src="/bjc-r/img/4-internet/one-third.png" alt="1 / 3"> with bignums off and with bignums on.</li></ol></div>
  <div class="takeNote">
  <p>Computer arithmetic on integers is straightforward.  Either you get an exactly correct result or, if the correct result wouldn't fit in the representation you're using, you get an <strong>overflow</strong> and the result is, usually, converted to floating point representation.  By contrast, computer arithmetic on floating point real numbers is very, very hard to get exactly right.  Prior to 1985, every model of computer had a slightly different floating point format, and all of them got wrong answers to certain problems.  This situation was resolved by the
    <strong>IEEE 754</strong> floating point standard, designed by &#x263a; University of California, Berkeley Professor William Kahan, a mathematician and computer scientist who did the first truly adequate analysis of what's required to get answers to floating point computations that are as correct as possible given a limited number of bits.  Today every computer manufacturer uses Professor Kahan's standard (which has been improved several times since 1985).</p>
</div>
<p>Here's the binary representation of 20! in 64-bit integer format:</p>
<p>0010000111000011011001110111110001000010101101000000000000000000</p>
<p>As an integer, that pattern of bits represents 243290200817664000. But <em>that same pattern of bits</em> represents</p>
<p>4.85611351839403586987046017196×10<sup>-146</sup></p>
<p>when considered as a floating point representation. The same pattern of bits may <em>also</em> represent an instruction in the machine language of whatever computer you're using. This is so important we're going to say it in boldface: <span style="background-color: orange"><strong>The meaning of a sequence of bits depends on the context in which it is used.</strong></span> That's the take-away understanding you should get from this page, after you've forgotten details such as how many bits there are in a floating point exponent field.</p>
<p>What exactly do we mean by &quot;context&quot;? How does a programming language know whether to interpret a bit sequence as an integer, a float, a string of characters, an instruction, or something else? Here, too, there is a distinction between good and bad programming languages. In both cases, there's <em>another</em> bit sequence somewhere that encodes the <strong>data type</strong> of the bit sequence. In good languages, that data type code is attached to the value itself. In bad languages, when you make a variable, you have to say what type of value it will contain, and the data type is attached to the <em>variable</em>, so you can't change your mind later. So instead of seeing</p>
<p><img src="/bjc-r/img/4-internet/varfoo.png" alt="script variables (foo)"></p>
<p>you see things like</p>
<p><img src="/bjc-r/img/4-internet/intfoo.png" alt="integer (foo)"></p>
<p>(We're telling you all these things about bad programming languages not just because it's fun, but also because it's very likely that your <em>next</em> year's computer science class will use a bad language. For example, if you take the AP Computer Science A course, it'll use Java. So you should understand what to expect.)</p>

</body>
</html>
<div class="todo">
Why this?  This page is making the point that it's /programmability/ that
heralds the huge leap to modern computing, and that it was invented 200 years
ago, well before it could actually be made practical.

Why here?  Following up on the first-page abstraction diagram, this is
focusing in on the hardware/software barrier.
</div>

<H1>The General Purpose Computer</H1>

So, there's no definitive answer to "when was the first computer."
Nevertheless, most people point to the work of Charles Babbage (1791-1871) as
the real beginning of the computer.  What was special about Babbage's work?

<H2>The Difference Engine</H2>

charles-babbage.jpg

Public domain

Babbage was an expert in several fields, but the one most relevant to our
story was his skill at creating mechanisms out of precisely milled metal
gears.  He used these to design a very complex machine that would
automatically compute and print tables of numbers, like the tables of log or
trig functions you may have in the back of a math textbook.  In Babbage's
time, such tables were computed by hand, by human mathematicians, and typeset
by hand for printing.  Both the computation and the copying into type were
error-prone, and accurate tables were needed for purposes ranging from
engineering to navigation.

Babbage built a first, small Difference Engine in 1822.  This first effort
proved that a Difference Engine was possible, but it didn't have the precision
(number of digits in each number) to be practical.  In 1823, the British
government funded Babbage to build a larger version.  Unfortunately,
metalsmiths in his day could not produce very precise gears in large
quantities; each one had to be handmade.  So he spent ten times his approved
budget by the time the government cancelled the project in 1842.

babbage-difference-engine.jpg

Wikimedia user User:geni.  Copyright 2008.  License: GFDL, CC BY-SA.

closeup-difference.jpg

Carsten Ullrich.  Copyright 2005.  License: CC-BY-SA-2.5.

In 1991, the London Science Museum completed a Difference Engine following
Babbage's original design, using gears made by modern processes but at the
level of precision that was available to Babbage.  This proved that in
principle Babbage could have completed a working machine, given enough time
and money.

<H2>The Analytical Engine</H2>

The Difference Engine could compute many different functions, by manually
setting the starting position of various gears.  But it had only one
algorithm, built into the hardware design.  In 1833, Babbage began work on a
much more ambitious project, the Analytical Engine.  It was based on the
general idea of the Difference Engine, but with a crucial difference:  It
could carry out instructions in a primitive programming language, prepared on
punched cards.

punched-cards-analytical-engine.jpg

Karoly Lorentey.  Copyright 2004.  License: CC-BY.

The Analytical Engine, like modern computers, had an arithmetic processor
(called the "mill") and a separate memory (the "store") that would hold 1,000
numbers, each with up to 40 digits.  (In modern terms, this is comparable to
20,000 bytes, since a byte can hold two digits, with four bits needed for
each.)  The programming language included conditionals and looping.  (It could
move forward or backward through the punched cards containing the program.)

Alas, Babbage could build only a small part of the Analytical Engine, which
would have required even more metalworking than the Difference Engine.  His
notes about the design weren't complete, and so nobody has built a working
model, although there are simulations available on the Web.

http://www.fourmilab.ch/babbage/contents.html

http://www.fourmilab.ch/babbage/emulator.html

So, almost 200 years ago, Babbage created plans for what is essentially a
modern computer, although he didn't have electronics available; his underlying
hardware was entirely mechanical.  Users would turn a crank to run the
machine; one or more turns of the crank would carry out one instruction in the
program.  In the early days of electronic computers, Babbage's work was not
widely available, and people had to reinvent many of Babbage's ideas.

<H2>The First Programmer</H2>

ada-lovelace.jpg

By <a href="https://en.wikipedia.org/wiki/Alfred_Edward_Chalon" class="extiw"
title="en:Alfred Edward Chalon">Alfred Edward Chalon</a> - <a rel="nofollow"
class="external text"
href="http://www.scienceandsociety.co.uk/results.asp?image=10312035">Science
&amp; Society Picture Library</a>, Public Domain, <a
href="https://commons.wikimedia.org/w/index.php?curid=28131684">Link</a>

Although his design was very versatile, Babbage himself was still mainly
interested in printing tables of numbers.  It was his collaborator Augusta Ada
King-Noel, Countess of Lovelace, who first recognized that the numbers in
Babbage's computer could be used not only as quantities but also as
representing musical notes, text characters, and so on.  Much of what we know
today about Babbage's design comes from Ada Lovelace's extensive notes on its
design.  Those notes included the first published program for the Analytical
Engine, and so she is widely considered "the first programmer," although
experts differ about how much was her own invention and how much was actually
written by Babbage himself.  But, whether or not she was truly the first
programmer, historians all agree that she invented the idea of
<em>symbolic</em> computation, as opposed to numeric computation.  This
insight paved the way for all the ways that computers are used today, from
movies on demand to voice-interactive programs such as Siri and Alexa.

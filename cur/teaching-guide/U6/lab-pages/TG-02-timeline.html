<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<script type="text/javascript" src="/bjc-r/llab/loader.js"></script>
		<title>Unit 6 Lab 1: A Timeline of Computers, Page 2</title>
    <style type="text/css">
    most-important {
	color: #F00;
}
    </style>
	</head>
    <body>
        <h2>A Brief History of Computers</h2>
        <h3>Timeline</h3>
        <div class="todo">
          <ul>
                <li><a href="#timeline-hollerith" data-toggle="collapse" class="collapsed" title="Hint"><em>First Punched Card Tabulator</em> (1890)</a><br />
            Herman Hollerith: Produced summaries of US Census data.</li>
                <li><a href="#timeline-analog" data-toggle="collapse" class="collapsed" title="Hint">Analog Computers (c. 1900)</a><br />
Special-purpose computers not based on zeros and ones.</li>
                <li><a href="#timeline-enigma" data-toggle="collapse" class="collapsed" title="Hint">Enigma (1930s)</a><br />
German mechanical computer for encoding secret messages.</li>
                <li><a href="#timeline-church" data-toggle="collapse" class="collapsed" title="Hint"><strong>Lambda Calculus, Undecidability</strong> (1936)</a><br />
Alonzo Church: Theoretical basis for <em>functional</em> programming.</li>
                <li><a href="#timeline-turing-machine" data-toggle="collapse" class="collapsed" title="Hint"><strong>Turing Machine, Halting Theorem</strong> (1936)</a><br />
Alan Turing: Theoretical basis for imperative programming.</li>
                <li><a href="#timeline-lisp" data-toggle="collapse" class="collapsed" title="Hint">LISP (1958)</a><br />
            John McCarthy: First functional programming language, still widely used.</li>
                <li><a href="#timeline-tcp-ip" data-toggle="collapse" class="collapsed" title="Hint">TCP/IP (1970s)</a><br />
            The design of the core protocols that run the Internet.</li>
                <li><a href="#timeline-alto" data-toggle="collapse" class="collapsed" title="Hint"><em>Xerox Alto</em> (1973)</a><br />
Alan Kay: Legendary prototype for personal interactive computing.</li>
                <li><a href="#timeline-first-pc" data-toggle="collapse" class="collapsed" title="Hint">First Personal Computer (1974)</a><br />
Altair 8800: First 8-bit personal computer.</li>
                <li><a href="#timeline-apple-ii" data-toggle="collapse" class="collapsed" title="Hint">Apple II (1977)</a><br />
Steve Wozniak: First mass-market personal computer.</li>
                <li><a href="#timeline-ibm-pc" data-toggle="collapse" class="collapsed" title="Hint">IBM PC (1981)</a><br />
First 16-bit computer marketed to businesses.</li>
                <li><a href="#timeline-mac" data-toggle="collapse" class="collapsed" title="Hint">Apple Macintosh (1984)</a><br />
First widely available computer using the ideas from the Alto: controlled mainly by mouse clicks rather than keyboard.    </li>
          </ul>
    </div>
        
        <img class="imageLeft" src="/bjc-r/img/6-computers/computer-history-timeline.png" alt="timeline of computer history" title="timeline of computer history" />
        
        <div id="timeline-tally" class="timeline collapse">
        	<div class="endnote">
            	<h4><strong>Tally Sticks</strong> (c. 18,000 BCE)</h4>
            	<p>20,000 years ago people cut patterns of notches into animal bones. Some experts believe that these <em>tally sticks</em> were used to perform arithmetic computations.</p>
            </div>
        </div>
        
        <div id="timeline-abacus" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The Abacus</strong> (c. 2,000 BCE)</h4>
                <p>The <em>abacus</em> is a computing device that was  invented about 4,000 years ago. It  can be used to do arithmetic,  including square roots and cube roots, on multi-digit numbers. In some countries, the abacus is still widely used today. People who are well-trained to use it can perform calculations remarkably quickly.</p>
                <div class="sidenote">
                	<small>Image by <a href="https://fr.wikipedia.org/wiki/Utilisateur:HB" class="extiw" title="fr:Utilisateur:HB">HB</a> - <span class="int-own-work" lang="en">Own work</span>, Public Domain, from Wikimedia.</small>
                </div>
				<img src="/bjc-r/img/6-computers/abacus.jpg" alt="an abacus (a.k.a. a counting frame), a calculating tool used before written numerals" title="an abacus (a.k.a. a counting frame), a calculating tool used before written numerals" />
            </div>
        </div>
        
        <div id="timeline-orrery" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The Orrery</strong> (c. 100 BCE)</h4>
                <p>
                    Since antiquity, many <em>special-purpose</em> computing devices have been invented. For example this <em>orrery</em> displayed the positions of the planets in the Solar System. The first known device of this kind dated from about 2100 years ago. People at that time generally believed that the sun and  other planets all revolved around the Earth, making the positions  very complicated to work out, so the mechanism was much harder to design and build than it would be today.
                    <div class="sidenote">
                        <small>No machine-readable image author provided. <a href="https://en.wikipedia.org/wiki/File:NAMA_Machine_d%27Anticyth%C3%A8re_1.jpg" target="_blank">Marsyas assumed</a> (based on copyright claims). GFDL, CC-BY-SA-3.0, or CC BY 2.5, via Wikimedia Commons.</small>
                    </div>
                    <img src="/bjc-r/img/6-computers/orrery1.jpg" alt="Gears from an ancient orrery" title="Gears from an ancient orrery" />
                </p>
                <p>
                    Here is a modern example of an orrery.
                    <div class="sidenote">
                        <small>Image by <a href="https://www.flickr.com/photos/kaptainkobold/127601212/sizes/m/" target="_blank">Kaptain Kobold</a>, licensed under the Creative Commons Attribution 2.0</small>
                    </div>
                    <img src="/bjc-r/img/6-computers/orrery2.jpg" alt="A modern orrery: mechanical model of planets" title="A modern orrery: mechanical model of planets" />
                </p>
            </div>
        </div>
        
        <div id="timeline-difference-engine" class="timeline collapse">
            <div class="endnote">            
                <h4><strong>The Difference Engine</strong> (c. 1822 CE)</h4>
                <p>
                	In 1822, Charles Babbage designed a device he called a "Difference Engine." Made  of precisely milled metal gears, it would compute and print tables of numbers, like log or trig functions. Accurate tables were needed for purposes ranging from engineering to navigation, but back then, such tables were computed by hand and hand-typeset for printing and both steps were error-prone. 
					<div class="sidenote">
                    	<small>Image of the Difference Engine at the London Science Museum by Wikimedia user geni. Copyright 2008. License: GFDL, CC BY-SA.</small>
                    </div>
					<img class="indent" src="/bjc-r/img/6-computers/babbage-difference-engine.jpg" alt="The Difference Engine at the London Science Museum" title="The Difference Engine at the London Science Museum" />
                </p>
				<p>
                    Babbage built a model proving that it could work, but his model was too small to have the precision to be practical. In 1823, the British government funded Babbage to build a larger version.  Unfortunately, metalsmiths in his day could not produce very precise gears quickly; each one had to be hand made. So he spent ten times his approved budget by the time the government cancelled the project in 1842.
                    <div class="sidenote">
                        <small>Closeup image showing the gears more clearly from Carsten Ullrich. Copyright 2005. License: CC-BY-SA-2.5.</small>
                    </div>
                    <img src="/bjc-r/img/6-computers/closeup-difference-eng.jpg" alt="A closeup showing the gears more clearly." title="A closeup showing the gears more clearly." />
                </p>
                <p>Almost 150 years later, the London Science Museum completed a working Difference Engine following Babbage's original design. Babbage could have done it himself if he'd had enough time and money!</p>
            </div>
        </div>
        
        <div id="timeline-analytical-engine" class="timeline collapse">
            <div class="endnote">
                <h4><strong>The Analytical Engine</strong> (c. 1833 CE)</h4>
                <p>
                	The Difference Engine could compute various functions by manually setting the starting position of its gears, but it had only one algorithm, built into the hardware design.  In 1833, Babbage began a  more ambitious project, the Analytical Engine.  It was based on the general idea of the Difference Engine, but with a crucial difference:  It could carry out instructions in a primitive programming language, prepared on punched cards.
      <div class="sidenote">
                        <small>Image of punched cards used to program the Analytic Engine by Karoly Lorentey. Copyright 2004. License: CC-BY.</small>
                    </div>
                    <img src="/bjc-r/img/6-computers/punched-cards-analytical-engine.jpg" alt="punched cards used to program the Analytic Engine" title="punched cards used to program the Analytic Engine" />
                </p>
                <p>Like modern computers, the Analytical Engine had an arithmetic processor (called the "mill") and a separate memory (the "store") that would seem tiny by today's standards. The mill did its arithmetic in decimal, with digits 0 through 9  equally spaced around each gear.  The programming language included conditionals and looping,  all you need to represent any algorithm.  It could loop because it could move forward or backward through the punched cards.</p>
                <p>The Analytical Engine would have required even more metalworking than the Difference Engine so Babbage could build only a small part.  His design notes  weren't complete,  so nobody has built a working model, although you can find simulations  on the Web.</p>
              <p>So, almost 200 years ago, Babbage created plans for what is essentially a modern computer, though mechanical, not electronic.  Users would turn a crank to run the machine; one or more turns of the crank would carry out one instruction in the program.  In the early days of electronic computers, Babbage's work was not widely known, and people ended up reinventing many of his ideas.</p>
                <p>Babbage's design was also not quite the modern form of a stored program architecture, because the program memory was separate from the data memory.  That meant that the computer couldn't produce a program for itself. Modern computers can not only <em>run</em> programs, but can be programmed to <em>modify</em> and even <em>create</em> their own programs.</p>
            </div>
        </div>
        
        <div id="timeline-first-programmer" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The First Programmer</strong> (c. 1842 CE)</h4>
                <p>Babbage's design was very versatile, but his interest was still mainly in printing tables of numbers. It was his collaborator Ada Lovelace, who first recognized that the numbers in Babbage's computer could be used not only as quantities but also as representing musical notes, text characters, and so on. She is widely considered "the first programmer" because, along with her extensive notes on the Analytical Engine—much of what we know today about its design—she included its first published program.</p>
                <p>Historians credit her with something even more important: she invented the idea of <em>symbolic</em> computation, as opposed to numeric computation.  This insight paved the way for all the ways that computers are used today, from movies on demand to voice-interactive programs such as Siri and Alexa.</p>        
            </div>
        </div>
        
        <br clear="all" />

		<div class="todo">
            <ul>
                <li><strong>Sketchpad</strong>:  Ivan Sutherland's 1963 Ph.D. thesis project, a program to help in
                drawing blueprints from points, line
                segments and arcs of circles.  It pioneered both the ability to draw on a screen
                (using a light pen; the mouse hasn't been invented yet) and object
            oriented programming.</li>
                
                <li><strong>Mouse, windows, and joint work on a single document</strong>:  <strong>(early 1960s) </strong>Douglas Engelbart had a lifelong interest in using technology to augment
                human intelligence,  in particular to support collaboration among people
                physically distant.  
                  <!-- The name comes from "oN-Line System" because he also had
                an "oFf-Line System" that's no longer important. -->
                  He studied people doing
                intellectual work and noted that when they're not using a computer they don't
                sit rigidly in front of their desks; they wheel their chairs around the room as
                they grab books or just think.  So he
                designed an office chair attachment of a lapboard containing a keyboard and a
                mouse—the first mouse.  
                  <!-- (Also a "chord keyboard" with
                five piano-key-like buttons so that you could position small amounts of text
                without having to move your hands back and forth between keyboard and mouse.) -->
                He also invented a way for  people to collaborate on the same page at the same time, seeing
                each others' mouse cursors.  Documents created in the system had hyperlinks to
                other documents, long before the Web used this idea.  There were lots of
                smaller firsts, too, such as a picture-in-picture display of the other person's
                face camera, long before Skype.
                
  People remember Engelbart mostly  because of the mouse, but he pioneered many features of the modern graphical user interface (GUI).</li>
                
                <li>* <strong>analog computer</strong>
                
                c. 1900 In analog computers,  a wire wasn't either fully on or fully off,
                but could carry any voltage (continuously variable) in the machine's operating
                range.  Because all voltages were legal, these machines suffered from
                electronic noise and so their precision was
                limited, typically to two or three decimal digits.  But for a certain class of
                problems—in particular, solving differential equations—these machines were a 
            natural fit.  They were programmed with plugboards, like ENIAC.</li>
                
                <li>* <strong>Hollerith's punch card tabulator for the Census</strong>
                
                Before the programmable digital computer, the first "big data" application was
                the US Census. Hollerith developed a system of storing
                information encoded by punching holes in cardboard cards.  These cards were processed by non-programmable "tabulating equipment,"
                such as a card sorter, that could take a deck of cards and arrange them in
                numeric order based on a subset of the columns.  Hollerith's technology was bought by IBM and was the beginning of their
          involvement in computation.</li>
                
                <li>* <strong>networked instant messaging</strong> (K. Harrenstein and B. Harvey)  :-)
                
                What we didn't invent was a centralized database of who's logged in on what
                computer; you had to know that the person you want to send a message to is at
                MIT, or is at Stanford.  (I'm not sure anyone else actually implemented this,
                although it was registered as an official Arpanet protocol, meaning just that
                we announced it in that RFC.)</li>
                
                <li><strong>the Enigma machine,
              Turing wins WWII</strong> [[There is text about this in the <a href="http://localhost/bjc-r/cur/programming/5-algorithms/4-unsolvable-undecidable/2-halting-problem.html?topic=nyc_bjc%2F5-algorithms.topic&course=bjc4nyc.html&novideo&noassignment">unsolvable problem lab in U5</a>.]]</li>
                
                <li><strong>ENIAC programmers</strong> (include http://eniacprogrammers.org/see-the-film/ in TG),
                first widely used mechanical calculators (e.g., something from NCR or Monroe or IBM),</li>
                
                <li><strong>first personal computers</strong> (1974). Prior to this time, computers were essentially huge, expensive devices owned only by universities, some large businesses, and a small number of other well-funded institutions.
                
                <!-- [[Earlier than that, I think.  The Mac was (unforgettably) 1984, and the Apple II
                was several years before that, and the Altair was even earlier.
                
                I think it's worth saying that the idea of interactive computing is way older
                than that wave of small machines.  Back when computers were big and expensive,
                there were interactive terminals connected to timesharing systems, starting no
                later than CTSS in 1961.  The deep idea here is that pioneers develop ideas
                that are a little beyond the capabilities of the underlying technology, just as
                Logo was developed on a timesharing system but with the understanding that kids
                would eventually be able to run it on a personal computer.]] --></li>
                
                <li><strong>first smart phone</strong> early 1990s. Today's smartphones are vastly faster and more powerful and have vastly more memory than the huge multi-million dollar university computers of the  1970s. 
				</li>
                <li><strong>WWW</strong></li>
			</ul>
    </div>

		<div class="forYouToDo" id="first">
			<ol>
				<li>
                	Discussion:
                    <ul>
                        <li>Does a device have to be programmable to be a computer?</li>
                        <li>Does it have to operate by itself?</li>				   
                    </ul>
                </li>				   
			</ol>
		</div>
        
        <div class="takeNote">
            Here are two key ideas:
            <ul>
              <li><em>Software,</em> in the form of a program stored in the computer's memory, is, itself, a kind of abstraction. It is what makes a computer usable for more than one purpose.<br />
                    
              </li>
                <li>We didn't get <em>usable</em> computers until there was an underlying technology (the transistor) small enough, inexpensive enough, and fast enough to support the program abstraction.</li>
            </ul>
        </div>
            

	</body>
</html>


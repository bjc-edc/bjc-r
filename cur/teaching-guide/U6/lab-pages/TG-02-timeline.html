<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<script type="text/javascript" src="/bjc-r/llab/loader.js"></script>
		<title>Unit 6 Lab 1: A Timeline of Computers, Page 2</title>
    <style type="text/css">
    most-important {
	color: #F00;
}
    </style>
	</head>
    <body>
        <h2>A Brief History of Computers</h2>
        <h3>Timeline Extras</h3>
        <div class="todo">
          <ul>
                <li><a href="#timeline-hollerith" data-toggle="collapse" class="collapsed" title="Hint"><em>First Punched Card Tabulator</em> (1890)</a><br />
            Herman Hollerith: Produced summaries of US Census data.</li>
                <li><a href="#timeline-analog" data-toggle="collapse" class="collapsed" title="Hint">Analog Computers (c. 1900)</a><br />
Special-purpose computers not based on zeros and ones.</li>
                <li><a href="#timeline-enigma" data-toggle="collapse" class="collapsed" title="Hint">Enigma (1930s)</a><br />
German mechanical computer for encoding secret messages.</li>
                <li><a href="#timeline-church" data-toggle="collapse" class="collapsed" title="Hint"><strong>Lambda Calculus, Undecidability</strong> (1936)</a><br />
Alonzo Church: Theoretical basis for <em>functional</em> programming.</li>
                <li><a href="#timeline-turing-machine" data-toggle="collapse" class="collapsed" title="Hint"><strong>Turing Machine, Halting Theorem</strong> (1936)</a><br />
Alan Turing: Theoretical basis for imperative programming.</li>
                <li><a href="#timeline-lisp" data-toggle="collapse" class="collapsed" title="Hint">LISP (1958)</a><br />
            John McCarthy: First functional programming language, still widely used.</li>
                <li><a href="#timeline-tcp-ip" data-toggle="collapse" class="collapsed" title="Hint">TCP/IP (1970s)</a><br />
            The design of the core protocols that run the Internet.</li>
                <li><a href="#timeline-alto" data-toggle="collapse" class="collapsed" title="Hint"><em>Xerox Alto</em> (1973)</a><br />
Alan Kay: Legendary prototype for personal interactive computing.</li>
                <li><a href="#timeline-first-pc" data-toggle="collapse" class="collapsed" title="Hint">First Personal Computer (1974)</a><br />
Altair 8800: First 8-bit personal computer.</li>
                <li><a href="#timeline-apple-ii" data-toggle="collapse" class="collapsed" title="Hint">Apple II (1977)</a><br />
Steve Wozniak: First mass-market personal computer.</li>
                <li><a href="#timeline-ibm-pc" data-toggle="collapse" class="collapsed" title="Hint">IBM PC (1981)</a><br />
First 16-bit computer marketed to businesses.</li>
                <li><a href="#timeline-mac" data-toggle="collapse" class="collapsed" title="Hint">Apple Macintosh (1984)</a><br />
First widely available computer using the ideas from the Alto: controlled mainly by mouse clicks rather than keyboard.    </li>
          </ul>
    </div>
        

        
        <div id="timeline-hollerith" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>First Punched Card Tabulator</strong> (c. 1890)</h4>
                <p>Before the programmable digital computer, the first "big data" application was
                the US Census. Herman Hollerith developed a system of storing
                information encoded by punching holes in cardboard cards.  These cards were processed by non-programmable "tabulating equipment,"
                such as a card sorter, that could take a deck of cards and arrange them in
                numeric order based on a subset of the columns.  Hollerith's technology was bought by IBM and was the beginning of their
          involvement in computation.
                </p>
            </div></div>
        
        <div id="timeline-analog" class="timeline collapse">
          <div class="endnote">
           	<h4><strong>Analog Computers</strong> (c. 1900)</h4>
              <p>In analog computers,  a wire wasn't either fully on or fully off,
                but could carry any voltage (continuously variable) in the machine's operating
                range.  Because all voltages were legal, these machines suffered from
                electronic noise and so their precision was
                limited, typically to two or three decimal digits.  But for a certain class of
                problems—in particular, solving differential equations—these machines were a 
            natural fit.  (Babbage's Difference Engine solved a very similar class of problems, but with finite differences instead of continuous differentials.)</p>
            </div></div>
        
        <div id="timeline-enigma" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The Enigma</strong> (1930s)</h4>
                <p>
                </p></div></div>
        
        <div id="timeline-church" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>Lambda Calculus</strong> (1936)</h4>
                <p>
                </p></div></div>
        
        <div id="timeline-turing-machine" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The Turing Machine</strong> (1936)</h4>
                <p>
                </p></div></div>
        
        <div id="timeline-lisp" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>LISP</strong> (1958)</h4>
                <p>
                </p></div></div>
        
        <div id="timeline-tcp-ip" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>TCP/IP</strong> (1970s)</h4>
                <p>
                </p></div></div>
        
        <div id="timeline-alto" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The Xerox Alto</strong> (1973)</h4>
                <p>
                </p></div></div>
        
        <div id="timeline-first-pc" class="timeline collapse">
          <div class="endnote">
           	<h4><strong>The Altair 8800</strong> (1974)</h4>
              <div class="sidenoteBig">
            <img height="25%"  src="/bjc-r/img/6-computers/altair.jpg" alt="Altair 8800 computer"><br />  
             <small><small> Altair 8800 at the Computer History Museum<br />
              Todd Dailey, 2009, CC BY-SA 2.0</small></small></div>
            
              <p>The Altair was the first commercially successful desktop computer system in a box. The first microprocessor, the Intel 4004, came three years earlier, but during those three years anyone who wanted to use a microprocessor had to do a significant amount of engineering to combine the processor chip with memory and input/output circuitry. The Altair, with an eight-bit Intel 8080 processor chip, made it possible for hobbyists who were not electrical engineers to have a computer to program.</p>
              <p>Prior to this time, computers were essentially huge, expensive devices owned only by universities, some large businesses, and a small number of other well-funded institutions. 
              The Altair started a flood of inexpensive computers and computer kits. It was the beginning of the modern computer age.</p>
            </div></div>
        
        <div id="timeline-apple-ii" class="timeline collapse">
          <div class="endnote">
            	<h4><strong>The Apple II</strong> (1977)</h4>
              <div class="sidenoteBig">
         <img src="/bjc-r/img/6-computers/apple-ii.png" alt="Apple II with TV and cassette storage"><br /><small><small>Apple II, Panasonic RQ-2102 cassette, and TV<br />Photo credit: Carl Knoblock, Phil Pfeiffer </small></small></div>    
              <p>The Apple II, designed by Steve Wozniak using the eight-bit MOS Technology 6502 chip, was the first personal computer designed for the family market, rather than for intense hobbyists.  Because it included a keyboard, it used an ordinary TV set as its monitor, and it could use an audio cassette tape recorder as its external memory (instead of more expensive disk drives), people could buy one, unpack the box, plug it in, and it would be working.  It could display text and graphics in color, unlike earlier personal computer products. And it was inexpensive enough for parents to buy for their kids. </p>
            </div></div>
        
        <div id="timeline-ibm-pc" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The IBM PC</strong> (1981)</h4>
              <div class="sidenoteBig">
    <img src="/bjc-r/img/6-computers/ibm-pc.jpg" alt="original IBM PC"><br />
<small><small>    Original IBM PC (Model 5150) with monochrome monitor<br />
By Ruben de Rijcke - Own work, CC BY-SA 3.0, via Wikimedia</small></small></div>
                <p>Hi there.
                </p></div></div>
        
        <div id="timeline-mac" class="timeline collapse">
            <div class="endnote">
            	<h4><strong>The Apple Macintosh</strong> (1984)</h4>
                
                <p>
                </p></div></div>
                        
        <br clear="all" />

		<div class="todo">
            <ul>
                <li><strong>Sketchpad</strong>:  Ivan Sutherland's 1963 Ph.D. thesis project, a program to help in
                drawing blueprints from points, line
                segments and arcs of circles.  It pioneered both the ability to draw on a screen
                (using a light pen; the mouse hasn't been invented yet) and object
            oriented programming.</li>
                
                <li><strong>Mouse, windows, and joint work on a single document</strong>:  <strong>(early 1960s) </strong>Douglas Engelbart had a lifelong interest in using technology to augment
                human intelligence,  in particular to support collaboration among people
                physically distant.  
                  <!-- The name comes from "oN-Line System" because he also had
                an "oFf-Line System" that's no longer important. -->
                  He studied people doing
                intellectual work and noted that when they're not using a computer they don't
                sit rigidly in front of their desks; they wheel their chairs around the room as
                they grab books or just think.  So he
                designed an office chair attachment of a lapboard containing a keyboard and a
                mouse—the first mouse.  
                  <!-- (Also a "chord keyboard" with
                five piano-key-like buttons so that you could position small amounts of text
                without having to move your hands back and forth between keyboard and mouse.) -->
                He also invented a way for  people to collaborate on the same page at the same time, seeing
                each others' mouse cursors.  Documents created in the system had hyperlinks to
                other documents, long before the Web used this idea.  There were lots of
                smaller firsts, too, such as a picture-in-picture display of the other person's
                face camera, long before Skype.
                
  People remember Engelbart mostly  because of the mouse, but he pioneered many features of the modern graphical user interface (GUI).</li>
                
                <li>* <strong>analog computer</strong>
                
                c. 1900 In analog computers,  a wire wasn't either fully on or fully off,
                but could carry any voltage (continuously variable) in the machine's operating
                range.  Because all voltages were legal, these machines suffered from
                electronic noise and so their precision was
                limited, typically to two or three decimal digits.  But for a certain class of
                problems—in particular, solving differential equations—these machines were a 
            natural fit.  They were programmed with plugboards, like ENIAC.</li>
                
                <li>* <strong>Hollerith's punch card tabulator for the Census</strong>
                
                Before the programmable digital computer, the first "big data" application was
                the US Census. Hollerith developed a system of storing
                information encoded by punching holes in cardboard cards.  These cards were processed by non-programmable "tabulating equipment,"
                such as a card sorter, that could take a deck of cards and arrange them in
                numeric order based on a subset of the columns.  Hollerith's technology was bought by IBM and was the beginning of their
          involvement in computation.</li>
                
                <li>* <strong>networked instant messaging</strong> (K. Harrenstein and B. Harvey)  :-)
                
                What we didn't invent was a centralized database of who's logged in on what
                computer; you had to know that the person you want to send a message to is at
                MIT, or is at Stanford.  (I'm not sure anyone else actually implemented this,
                although it was registered as an official Arpanet protocol, meaning just that
                we announced it in that RFC.)</li>
                
                <li><strong>the Enigma machine,
              Turing wins WWII</strong> [[There is text about this in the <a href="http://localhost/bjc-r/cur/programming/5-algorithms/4-unsolvable-undecidable/2-halting-problem.html?topic=nyc_bjc%2F5-algorithms.topic&course=bjc4nyc.html&novideo&noassignment">unsolvable problem lab in U5</a>.]]</li>
                
                <li><strong>ENIAC programmers</strong> (include http://eniacprogrammers.org/see-the-film/ in TG),
                first widely used mechanical calculators (e.g., something from NCR or Monroe or IBM),</li>
                
                <li><strong>first personal computers</strong> (1974). Prior to this time, computers were essentially huge, expensive devices owned only by universities, some large businesses, and a small number of other well-funded institutions.
                
                <!-- [[Earlier than that, I think.  The Mac was (unforgettably) 1984, and the Apple II
                was several years before that, and the Altair was even earlier.
                
                I think it's worth saying that the idea of interactive computing is way older
                than that wave of small machines.  Back when computers were big and expensive,
                there were interactive terminals connected to timesharing systems, starting no
                later than CTSS in 1961.  The deep idea here is that pioneers develop ideas
                that are a little beyond the capabilities of the underlying technology, just as
                Logo was developed on a timesharing system but with the understanding that kids
                would eventually be able to run it on a personal computer.]] --></li>
                
                <li><strong>first smart phone</strong> early 1990s. Today's smartphones are vastly faster and more powerful and have vastly more memory than the huge multi-million dollar university computers of the  1970s. 
				</li>
                <li><strong>WWW</strong></li>
			</ul>
    </div>

		<div class="forYouToDo" id="first">
			<ol>
				<li>
                	Discussion:
                    <ul>
                        <li>Does a device have to be programmable to be a computer?</li>
                        <li>Does it have to operate by itself?</li>				   
                    </ul>
                </li>				   
			</ol>
		</div>
        
        <div class="takeNote">
            Here are two key ideas:
            <ul>
              <li><em>Software,</em> in the form of a program stored in the computer's memory, is, itself, a kind of abstraction. It is what makes a computer usable for more than one purpose.<br />
                    
              </li>
                <li>We didn't get <em>usable</em> computers until there was an underlying technology (the transistor) small enough, inexpensive enough, and fast enough to support the program abstraction.</li>
            </ul>
        </div>
            

	</body>
</html>

